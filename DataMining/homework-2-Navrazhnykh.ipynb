{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2. Преобразование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель этого задания -- преобразовать имеющиеся атрибуты пользователей в признаки так, чтобы полученная матрица признаков была пригодна для подачи в алгоритм кластеризации. Этап конструирования признаков -- самый важный и обычно самый долгий. К нему возвращаются много раз на протяжении решения задачи анализа данных.\n",
    "\n",
    "Кроме библиотек, использованных в первом задании, нам понадобятся следующие библиотеки:\n",
    "1. [scikit-learn](http://scikit-learn.org/stable/) -- библиотека, реализующая множество алгоритмов машинного обучения и сопутствующих алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import sklearn.preprocessing as sp\n",
    "import csv\n",
    "import re\n",
    "import dateutil\n",
    "\n",
    "np.set_printoptions(linewidth=150, precision=3, suppress=True)\n",
    "\n",
    "# Plotting config\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_parser = lambda date_str: datetime.datetime.strptime(date_str, \"%Y-%m\") if pd.notnull(date_str) and date_str else None\n",
    "df_users = pd.read_csv(\"hw1_out.csv\", sep=\"\\t\", encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC, converters={\"created_at\": ts_parser}).drop('country_code', 1)\n",
    "# Remove rows with users not found\n",
    "df_users = df_users[pd.notnull(df_users['name'])]\n",
    "#df_users[\"lat\"].fillna(value=0, inplace=True)\n",
    "#df_users[\"lon\"].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>cat</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>description</th>\n",
       "      <th>verified</th>\n",
       "      <th>location</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>country</th>\n",
       "      <th>created_at</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40585382</td>\n",
       "      <td>1</td>\n",
       "      <td>Reverend Sue</td>\n",
       "      <td>ReverendSue</td>\n",
       "      <td>Retired Interfaith Minister. Activist. Equalit...</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>-98.50000</td>\n",
       "      <td>39.76000</td>\n",
       "      <td>United States</td>\n",
       "      <td>2009-05-01</td>\n",
       "      <td>7604</td>\n",
       "      <td>4282</td>\n",
       "      <td>50614</td>\n",
       "      <td>787</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30005269</td>\n",
       "      <td>0</td>\n",
       "      <td>Ryan Wrasse</td>\n",
       "      <td>RWrasse</td>\n",
       "      <td>Communications Director for @SenJohnThune | Ge...</td>\n",
       "      <td>False</td>\n",
       "      <td>Capitol Hill</td>\n",
       "      <td>145.75313</td>\n",
       "      <td>15.20825</td>\n",
       "      <td>Northern Mariana Islands</td>\n",
       "      <td>2009-04-01</td>\n",
       "      <td>1920</td>\n",
       "      <td>1241</td>\n",
       "      <td>7162</td>\n",
       "      <td>127</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3314758074</td>\n",
       "      <td>0</td>\n",
       "      <td>Campaign Trump</td>\n",
       "      <td>MooreJohnvii</td>\n",
       "      <td>#AlwaysTrump for President. Indp Local &amp; Inter...</td>\n",
       "      <td>False</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>-82.50010</td>\n",
       "      <td>28.75054</td>\n",
       "      <td>United States</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>24912</td>\n",
       "      <td>12404</td>\n",
       "      <td>2305</td>\n",
       "      <td>7807</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14311688</td>\n",
       "      <td>0</td>\n",
       "      <td>Bernard Whitman</td>\n",
       "      <td>BernardWhitman</td>\n",
       "      <td>Democratic strategist, pollster, and corporate...</td>\n",
       "      <td>False</td>\n",
       "      <td>New York</td>\n",
       "      <td>-74.00597</td>\n",
       "      <td>40.71427</td>\n",
       "      <td>United States</td>\n",
       "      <td>2008-04-01</td>\n",
       "      <td>1770</td>\n",
       "      <td>1298</td>\n",
       "      <td>7382</td>\n",
       "      <td>176</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110457801</td>\n",
       "      <td>0</td>\n",
       "      <td>Carson Ingle</td>\n",
       "      <td>caingle</td>\n",
       "      <td>Writer for @AthleteSpeakers &amp; @NOPACTalent. 10...</td>\n",
       "      <td>False</td>\n",
       "      <td>Orlando aka The City Beautiful</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>1481</td>\n",
       "      <td>1189</td>\n",
       "      <td>37228</td>\n",
       "      <td>3327</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          uid  cat             name     screen_name  \\\n",
       "0    40585382    1     Reverend Sue     ReverendSue   \n",
       "1    30005269    0      Ryan Wrasse         RWrasse   \n",
       "2  3314758074    0   Campaign Trump    MooreJohnvii   \n",
       "3    14311688    0  Bernard Whitman  BernardWhitman   \n",
       "4   110457801    0     Carson Ingle         caingle   \n",
       "\n",
       "                                         description verified  \\\n",
       "0  Retired Interfaith Minister. Activist. Equalit...    False   \n",
       "1  Communications Director for @SenJohnThune | Ge...    False   \n",
       "2  #AlwaysTrump for President. Indp Local & Inter...    False   \n",
       "3  Democratic strategist, pollster, and corporate...    False   \n",
       "4  Writer for @AthleteSpeakers & @NOPACTalent. 10...    False   \n",
       "\n",
       "                         location        lat       lon  \\\n",
       "0                   United States  -98.50000  39.76000   \n",
       "1                    Capitol Hill  145.75313  15.20825   \n",
       "2                    Florida, USA  -82.50010  28.75054   \n",
       "3                        New York  -74.00597  40.71427   \n",
       "4  Orlando aka The City Beautiful        NaN       NaN   \n",
       "\n",
       "                    country created_at  followers_count  friends_count  \\\n",
       "0             United States 2009-05-01             7604           4282   \n",
       "1  Northern Mariana Islands 2009-04-01             1920           1241   \n",
       "2             United States 2015-08-01            24912          12404   \n",
       "3             United States 2008-04-01             1770           1298   \n",
       "4                       NaN 2010-02-01             1481           1189   \n",
       "\n",
       "   statuses_count  favourites_count  listed_count  \n",
       "0           50614               787           417  \n",
       "1            7162               127            97  \n",
       "2            2305              7807           217  \n",
       "3            7382               176           110  \n",
       "4           37228              3327            76  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее необходимо ввести новые признаки. Для каждого пользователя предлагается ввести следующие признаки:\n",
    "- name_words - количество слов в имени\n",
    "- screen_name_length - количество символов в псевдониме\n",
    "- description_length - длина описания\n",
    "- created_year - год создания аккаунта\n",
    "- country_code - код страны\n",
    "- verified - предлагается перевести в тип int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_new_features(df_users, features):\n",
    "    # Introduce new features\n",
    "    countries = list(set(df_users['country'].values))\n",
    "\n",
    "    new_features = {\"name_words\":[], \"screen_name_length\":[], \"description_length\":[], \"created_year\":[], \"country_code\":[], \"verified\":[]}    \n",
    "    for idx, user in df_users.iterrows():\n",
    "        new_features[\"name_words\"].append(len(user[\"name\"].split()))\n",
    "        new_features[\"screen_name_length\"].append(len(user[\"screen_name\"]))\n",
    "        try:\n",
    "            new_features[\"description_length\"].append(len(user['description']))\n",
    "        except:\n",
    "            new_features[\"description_length\"].append(0)\n",
    "        new_features[\"created_year\"].append(int(user['created_at'].year))\n",
    "        new_features['country_code'].append(countries.index(user['country']))\n",
    "        new_features['verified'].append(int(user['verified']))\n",
    "        \n",
    "    features.extend(new_features.keys())\n",
    "    df_features = pd.DataFrame(new_features, columns = new_features.keys())\n",
    "    df_features = pd.concat([df_users[df_users.columns.difference(['verified'])], df_features], axis = 1)\n",
    "    \n",
    "    return df_features, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [\"lat\", \"lon\", \"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\"]\n",
    "df_users, features = create_new_features(df_users, features)\n",
    "\n",
    "x = df_users[pd.notnull(df_users.cat)][features].values\n",
    "y = df_users[pd.notnull(df_users.cat)][\"cat\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cat                   country created_at  \\\n",
      "0    1             United States 2009-05-01   \n",
      "1    0  Northern Mariana Islands 2009-04-01   \n",
      "2    0             United States 2015-08-01   \n",
      "3    0             United States 2008-04-01   \n",
      "4    0                       NaN 2010-02-01   \n",
      "\n",
      "                                         description  favourites_count  \\\n",
      "0  Retired Interfaith Minister. Activist. Equalit...               787   \n",
      "1  Communications Director for @SenJohnThune | Ge...               127   \n",
      "2  #AlwaysTrump for President. Indp Local & Inter...              7807   \n",
      "3  Democratic strategist, pollster, and corporate...               176   \n",
      "4  Writer for @AthleteSpeakers & @NOPACTalent. 10...              3327   \n",
      "\n",
      "   followers_count  friends_count        lat  listed_count  \\\n",
      "0             7604           4282  -98.50000           417   \n",
      "1             1920           1241  145.75313            97   \n",
      "2            24912          12404  -82.50010           217   \n",
      "3             1770           1298  -74.00597           110   \n",
      "4             1481           1189        NaN            76   \n",
      "\n",
      "                         location         ...                     name  \\\n",
      "0                   United States         ...             Reverend Sue   \n",
      "1                    Capitol Hill         ...              Ryan Wrasse   \n",
      "2                    Florida, USA         ...           Campaign Trump   \n",
      "3                        New York         ...          Bernard Whitman   \n",
      "4  Orlando aka The City Beautiful         ...             Carson Ingle   \n",
      "\n",
      "      screen_name statuses_count         uid  verified  screen_name_length  \\\n",
      "0     ReverendSue          50614    40585382         0                  11   \n",
      "1         RWrasse           7162    30005269         0                   7   \n",
      "2    MooreJohnvii           2305  3314758074         0                  12   \n",
      "3  BernardWhitman           7382    14311688         0                  14   \n",
      "4         caingle          37228   110457801         0                   7   \n",
      "\n",
      "   created_year  name_words  country_code  description_length  \n",
      "0          2009           2            48                 116  \n",
      "1          2009           2             4                 154  \n",
      "2          2015           2            48                 144  \n",
      "3          2008           2            48                 114  \n",
      "4          2010           2             0                 151  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, являются ли какие-либо из выбранных признаков сильно скоррелированными. Для этого посчитаем матрицу корреляций и выберем те пары признаков, фбсолютное значения коэффициента корреляции между которыми больше 0.2. Необходимо реализовать функцию find_correlated_features, в которой нужно рассчитать коэффициенты корелляции и вывести те, которые больше 0.2. Подсказка: предлагается найти необходимую функцию в библиотеке np и реализовать find_correlated_features с использованием не более 5 строк кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_correlated_features(x, features):\n",
    "    matrix = np.corrcoef(x)\n",
    "    for i, feature_i in enumerate(features):\n",
    "        for j, feature_j in enumerate(features):\n",
    "            if i < j and abs(matrix[i, j]) > 0.2:\n",
    "                print \"Correlated features: %s + %s -> %.2f\" % (feature_i, feature_j, abs(matrix[i, j]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -98.5      39.76      2.296     2.237     2.471     2.037     1.951     0.       11.     2009.        2.       48.      116.   ]\n",
      "Correlated features: lat + lon -> 0.99\n",
      "Correlated features: lat + followers_count -> 1.00\n",
      "Correlated features: lat + friends_count -> 1.00\n",
      "Correlated features: lat + favourites_count -> 1.00\n",
      "Correlated features: lat + listed_count -> 1.00\n",
      "Correlated features: lat + verified -> 1.00\n",
      "Correlated features: lat + screen_name_length -> 1.00\n",
      "Correlated features: lat + created_year -> 1.00\n",
      "Correlated features: lat + country_code -> 1.00\n",
      "Correlated features: lat + description_length -> 1.00\n",
      "Correlated features: lon + followers_count -> 0.99\n",
      "Correlated features: lon + friends_count -> 0.99\n",
      "Correlated features: lon + favourites_count -> 0.99\n",
      "Correlated features: lon + listed_count -> 0.99\n",
      "Correlated features: lon + verified -> 0.99\n",
      "Correlated features: lon + screen_name_length -> 0.99\n",
      "Correlated features: lon + created_year -> 0.99\n",
      "Correlated features: lon + country_code -> 0.99\n",
      "Correlated features: lon + description_length -> 0.99\n",
      "Correlated features: followers_count + friends_count -> 1.00\n",
      "Correlated features: followers_count + favourites_count -> 1.00\n",
      "Correlated features: followers_count + listed_count -> 1.00\n",
      "Correlated features: followers_count + verified -> 1.00\n",
      "Correlated features: followers_count + screen_name_length -> 1.00\n",
      "Correlated features: followers_count + created_year -> 1.00\n",
      "Correlated features: followers_count + country_code -> 1.00\n",
      "Correlated features: followers_count + description_length -> 1.00\n",
      "Correlated features: friends_count + favourites_count -> 1.00\n",
      "Correlated features: friends_count + listed_count -> 1.00\n",
      "Correlated features: friends_count + verified -> 1.00\n",
      "Correlated features: friends_count + screen_name_length -> 1.00\n",
      "Correlated features: friends_count + created_year -> 1.00\n",
      "Correlated features: friends_count + country_code -> 1.00\n",
      "Correlated features: friends_count + description_length -> 1.00\n",
      "Correlated features: favourites_count + listed_count -> 1.00\n",
      "Correlated features: favourites_count + verified -> 1.00\n",
      "Correlated features: favourites_count + screen_name_length -> 1.00\n",
      "Correlated features: favourites_count + created_year -> 1.00\n",
      "Correlated features: favourites_count + country_code -> 1.00\n",
      "Correlated features: favourites_count + description_length -> 1.00\n",
      "Correlated features: listed_count + verified -> 1.00\n",
      "Correlated features: listed_count + screen_name_length -> 1.00\n",
      "Correlated features: listed_count + created_year -> 1.00\n",
      "Correlated features: listed_count + country_code -> 1.00\n",
      "Correlated features: listed_count + description_length -> 1.00\n",
      "Correlated features: verified + screen_name_length -> 1.00\n",
      "Correlated features: verified + created_year -> 1.00\n",
      "Correlated features: verified + country_code -> 1.00\n",
      "Correlated features: verified + description_length -> 1.00\n",
      "Correlated features: screen_name_length + created_year -> 1.00\n",
      "Correlated features: screen_name_length + country_code -> 1.00\n",
      "Correlated features: screen_name_length + description_length -> 1.00\n",
      "Correlated features: created_year + country_code -> 1.00\n",
      "Correlated features: created_year + description_length -> 1.00\n",
      "Correlated features: country_code + description_length -> 1.00\n"
     ]
    }
   ],
   "source": [
    "print x[0]\n",
    "find_correlated_features(x, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделилось 3 группы признаков:\n",
    "1. Основанные на географии:  \"lat\", \"lon\", \"country_code\"\n",
    "2. Основанные на социальной активности:  \"verified\", \"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\", \"created_year\"\n",
    "3. Остальные:  \"name_words\", \"screen_name_length\", \"description_length\"\n",
    "\n",
    "Построим взаимные распределения пар признаков в каждой из групп, а также гистограмму значений каждого из признаков с учетом целевой переменной."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Необходимо реализовать функции: plot_two_features_scatter для построения взаимного распределения пары признаков, plot_feature_histogram для построения гистограммы значений, plot_dataset для построения набора графиков по разным парам признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим попарные распределения географических признаков ([подсказка](http://anokhin.github.io/img/hw2_geo.png))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def plot_two_features_scatter(ax, x_j, x_i, y):\n",
    "    shuffle = 16\n",
    "\n",
    "    g, r = (y==0).nonzero(), y.nonzero()\n",
    "    \n",
    "    for i in xrange(shuffle):\n",
    "        ax.plot(x_i[g][i::shuffle], x_j[g][i::shuffle], 'og',\n",
    "                x_i[r][i::shuffle], x_j[r][i::shuffle], 'or')\n",
    "    \n",
    "def plot_feature_histogram(ax, x_i, y):\n",
    "    g, r = (y==0).nonzero(), y.nonzero()\n",
    "    \n",
    "    res_g, res_r = Counter(x_i[g]), Counter(x_i[r])\n",
    "    \n",
    "    for key, value in res_r.items():\n",
    "        ax.bar(key, value, color = 'r', bottom = res_g[key], edgecolor = \"none\")\n",
    "        \n",
    "    for key, value in res_g.items():\n",
    "        ax.bar(key, value, color = 'g', edgecolor = \"none\")\n",
    "\n",
    "def plot_dataset(x, y, features):\n",
    "\n",
    "    size = len(x[0])\n",
    "    fig, axes = pl.subplots(nrows=size, ncols=size, figsize=(17,14))\n",
    "    \n",
    "    pl.setp(axes, xticklabels=[], yticklabels=[])\n",
    "    for i in xrange(size):\n",
    "        axes[size-1, i].set_xlabel(features[i])\n",
    "        axes[i, 0].set_ylabel(features[i])\n",
    "   \n",
    "    for i in xrange(size):\n",
    "        for j in xrange(size):\n",
    "            if i != j:\n",
    "                plot_two_features_scatter(axes[i, j], x[:, i], x[:, j], y)            \n",
    "            else:\n",
    "                plot_feature_histogram(axes[i, j], x[:, i], y)\n",
    "                \n",
    "    pl.tight_layout()\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_features_new = [\"lat\", \"lon\", \"country_code\"]\n",
    "geo_features = [f for f in geo_features_new if f in features]\n",
    "\n",
    "geo_feature_ind = [features.index(i) for i in geo_features]\n",
    "#plot_dataset(x[:, geo_feature_ind], y, geo_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Четко видны очертания карты и то, что большинство пользователей происходят из небольшого набора стран. Если принять во внимание конечную цель -- кластеризацию пользователей -- логично предположить, что использование географических признаков для описания пользователя может оказаться не очень полезным. Причина в том, что эти признаки четко пространственно разделены (как минимум, океанами и морями). Поэтому мы рискуем вместо \"интересной\" кластеризации получить просто кластеры, которые будут представлять разные страны. В дальнейшем мы исключим географические признаки из рассмотрения при кластеризации пользователей.\n",
    "\n",
    "Далее построим попарные распределения социальных признаков ([подсказка](http://anokhin.github.io/img/hw2_social1.png))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "social_features_new = [\"verified\", \"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\", \"created_year\"]\n",
    "social_features = [f for f in social_features_new if f in features]\n",
    "social_feature_ind = [features.index(i) for i in social_features]\n",
    "#plot_dataset(x[:, social_feature_ind], y, social_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графиков видно, что признаки \"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\" сильно смещены в сторону небольших значений. В таком случае удобно сделать логарифмическое преобразрвание этих признаков, то есть применить к их значениям $x_{ij}$ функцию $\\log(1 + x_{ij})$. Сделаем это и построим новые распределения ([подсказка](http://anokhin.github.io/img/hw2_social2.png)). Необходимо реализовать функцию log_transform_features, которая выполняет указанное логарифмическое преобразование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_transform_features(data, features, transformed_features):\n",
    "    feature_ind = [features.index(i) for i in transformed_features]\n",
    "    data[:, feature_ind] = np.log(data[:, feature_ind] + 1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformed_features = [\"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\"]\n",
    "x = log_transform_features(x, features, transformed_features)\n",
    "\n",
    "# Re-plot features\n",
    "#plot_dataset(x[:, social_feature_ind], y, social_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу бросается в глаза, что признак \"verified\" сильно смещен -- верифицированных пользователей очень мало. Более того, все верифицированные пользователи имеют много фолловеров, поэтому часть информации о верификации дублируется в признаке \"followers_count\". По этой причине в дальнейшем не будем рассмтаривать признак \"verified\".\n",
    "\n",
    "После того как мы с помощью логарифмического преобразования избавились от сильной скошенности признаков, можно наблюдать некоторые интересные зависимости. Например, пользователи, имеющие много фолловеров, обязательно имеют много статусов. Следовательно, чтобы стать популярным, обязательно нужно много писать. Анализ других зависимостей остается как упражнение.\n",
    "\n",
    "Наконец построим попарные распределения остальных признаков ([подсказка](http://anokhin.github.io/img/hw2_other.png))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "other_features_new = [\"name_words\", \"screen_name_length\", \"description_length\"]\n",
    "other_features = [f for f in other_features_new if f in features]\n",
    "other_feature_ind = [features.index(i) for i in other_features]\n",
    "#lot_dataset(x[:, other_feature_ind], y, other_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак после первичной обработки данных мы имеем 9 числовых признаков, каждый из которых распределен в некотором своем интервале. Для того, чтобы ни один признак не получил перевеса при кластеризации, нормализуем данные так, что каждый признак распределен на отрезке $[0, 1]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 71086044.    800283.    699811.    484224.    214683.      2016.        10.        15.       160.]\n",
      "[ 31639.877   2084.712  14639.961   4527.66     308.517   2011.044      2.063     11.466    103.791]\n"
     ]
    }
   ],
   "source": [
    "selected_features = [\"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \n",
    "                     \"listed_count\", \"created_year\", \"name_words\", \"screen_name_length\", \"description_length\"]\n",
    "selected_features_ind = [i for i, f in enumerate(features) if f in selected_features]\n",
    "\n",
    "transformed_features = [\"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\"]\n",
    "\n",
    "#x_1 = log_transform_features(df_users[selected_features].dropna().values, selected_features, transformed_features)\n",
    "x_1 = df_users[selected_features].dropna().values\n",
    "\n",
    "#print x_1.shape\n",
    "#print df_users[selected_features].dropna().values.shape\n",
    "#y = df_users[\"cat\"].values\n",
    "\n",
    "# Replace nan with 0-s\n",
    "# Is there a smarter way?\n",
    "#x_1[np.isnan(x_1)] = 0\n",
    "\n",
    "x_min = x_1.min(axis=0)\n",
    "x_max = x_1.max(axis=0)\n",
    "print x_max\n",
    "print x_1.mean(axis=0)\n",
    "x_new = (x_1 - x_min) / (x_max - x_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Упакуем полученную матрицу в pandas DataFrame и сохраним в файл \"hw2_out.csv\". В следующем задании мы будем кластеризовать пользователей на оновании этих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(data=x_new, index=df_users[selected_features + [\"uid\"]].dropna()[\"uid\"], columns=[f for f in selected_features])\n",
    "df_out.to_csv(\"hw2_out.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
